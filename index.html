<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8">
    <title>Pythia AR Reader</title>
    <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">
    
    <!-- 1. Core AR Engine -->
    <script src="encantar.js"></script>
    
    <!-- 2. A-Frame (3D Engine) -->
    <script src="https://cdn.jsdelivr.net/npm/aframe@1.6.0/dist/aframe-v1.6.0.min.js"></script>
    
    <!-- 3. Integration Layer -->
    <script src="aframe-with-encantar.js"></script>

    <style>
      body { margin: 0; overflow: hidden; background-color: transparent; }
      #info {
        position: absolute;
        top: 10px;
        left: 10px;
        z-index: 999;
        color: white;
        font-family: sans-serif;
        background: rgba(0, 0, 0, 0.5);
        padding: 10px;
        pointer-events: none;
      }
    </style>
  </head>
  <body>
    <div id="info">
      <h3>Pythia</h3>
      <p>Point camera at the target image.</p>
    </div>

    <!-- 
      encantar="stats: true" enables the performance stats widget 
      gizmos: true shows debug lines for tracking 
    -->
    <a-scene encantar="stats: true; gizmos: true" vr-mode-ui="enabled: false">
      
      <!-- AR Configuration -->
      <ar-sources>
        <ar-camera-source resolution="lg" facing-mode="environment"></ar-camera-source>
      </ar-sources>

      <ar-viewport></ar-viewport>

      <ar-trackers>
        <!-- database-size: 'sm' | 'md' | 'lg' determines the dictionary size -->
        <ar-image-tracker resolution="lg" database-size="md">
          <ar-reference-image name="marker" src="marker.png"></ar-reference-image>
        </ar-image-tracker>
      </ar-trackers>

      <!-- 
        AR Content 
        Use <ar-root reference-image="name"> to attach content to a tracker.
      -->
      
      <ar-root reference-image="marker">
        <a-entity 
          id="ar-model"
          gltf-model="url(2geogen-asset.glb)" 
          position="0 0 0" 
          scale="0.5 0.5 0.5"
          animation="property: rotation; to: 0 360 0; loop: true; dur: 10000; easing: linear">
        </a-entity>
        
        <!-- Debug Box: Should be visible if AR is working -->
        <a-box position="0 0.5 0" scale="0.5 0.5 0.5" color="red" animation="property: rotation; to: 0 360 0; loop: true; dur: 5000"></a-box>
        
        <!-- Scale Test Boxes -->
        <a-box position="1 0 0" scale="10 10 10" color="green" material="opacity: 0.5"></a-box>
        <a-box position="-1 0 0" scale="100 100 100" color="blue" material="opacity: 0.5"></a-box>
        
        <!-- Optimized Lighting -->
        <a-light type="ambient" color="#ffffff" intensity="2.51"></a-light>
        <a-light type="directional" position="2 4 2" color="#ffffff" intensity="3.14" shadow="cast: true"></a-light>
        <a-light type="point" position="-1 2 1" color="#4CAF50" intensity="30" decay="2"></a-light>
        <a-light type="point" position="1 2 1" color="#2196F3" intensity="30" decay="2"></a-light>
      </ar-root>

      <!-- The Camera -->
      <ar-camera>
        <!-- HUD or fixed elements can go here -->
      </ar-camera>

    </a-scene>

    <script>
      // Simple event logging to verify the engine is running
      const scene = document.querySelector('a-scene');
      
      scene.addEventListener('arready', () => {
        console.log('AR System is ready!');
        document.querySelector('#info p').textContent = 'System Ready. Scanning...';
      });

      scene.addEventListener('artargetfound', (ev) => {
        const targetName = ev.detail.referenceImage.name;
        console.log(`Target found: ${targetName}`);
        document.querySelector('#info p').textContent = `Found: ${targetName}`;
      });

      scene.addEventListener('artargetlost', (ev) => {
        const targetName = ev.detail.referenceImage.name;
        console.log(`Target lost: ${targetName}`);
        document.querySelector('#info p').textContent = `Lost: ${targetName}`;
      });

      // Debug Model Loading
      const model = document.querySelector('#ar-model');
      model.addEventListener('model-loaded', () => {
        console.log('3D Model Loaded Successfully!');
        document.querySelector('#info p').textContent += ' | Model Loaded';
      });
      model.addEventListener('model-error', (e) => {
        console.error('3D Model Failed to Load:', e);
        document.querySelector('#info p').textContent += ' | Model Error!';
      });

      // Debug Coordinates
      setInterval(() => {
        const root = document.querySelector('ar-root');
        if (root && root.object3D && root.object3D.parent && root.object3D.parent.visible) {
          const pos = new THREE.Vector3();
          const scale = new THREE.Vector3();
          root.object3D.parent.getWorldPosition(pos);
          root.object3D.parent.getWorldScale(scale);
          
          const info = `Pos: ${pos.x.toFixed(1)}, ${pos.y.toFixed(1)}, ${pos.z.toFixed(1)} | Scale: ${scale.x.toFixed(2)}`;
          const p = document.querySelector('#info p');
          if (!p.textContent.includes('Pos:')) {
             p.textContent = p.textContent.split('| Pos:')[0] + ' | ' + info;
          } else {
             // Update existing pos text
             p.textContent = p.textContent.replace(/\| Pos:.*$/, '| ' + info);
          }
        }
      }, 500);
    </script>

    <!-- Adaptive tracker: fast acquisition (md) â†’ stable (lg) after 1s -->
    <script>
    (function adaptiveTrackerRes(){
      const tracker = document.querySelector('ar-image-tracker');
      const cam = document.querySelector('ar-camera-source');
      if (!tracker || !cam) return;

      // Ensure camera is high; start tracker easier to acquire
      cam.setAttribute('resolution', 'lg');
      tracker.setAttribute('resolution', 'md');

      let timer = 0;
      document.addEventListener('artargetfound', (ev)=>{
        const ref = ev.detail && ev.detail.referenceImage;
        if (ref && ref.name !== 'marker') return;
        clearTimeout(timer);
        timer = setTimeout(()=> tracker.setAttribute('resolution','lg'), 1000);
      });
      document.addEventListener('artargetlost', (ev)=>{
        const ref = ev.detail && ev.detail.referenceImage;
        if (ref && ref.name !== 'marker') return;
        clearTimeout(timer);
        tracker.setAttribute('resolution','md'); // easier relock if lost
      });
    })();
    </script>

    <!-- Camera focus/zoom for small marker recognition -->
    <script>
    (function tuneCamera() {
      // Retry until <video> has stream
      let tries = 0;
      const tick = async () => {
        tries++;
        const vid = document.querySelector('ar-viewport video, video');
        const track = vid && vid.srcObject && vid.srcObject.getVideoTracks && vid.srcObject.getVideoTracks()[0];
        if (!track) { if (tries < 30) setTimeout(tick, 300); return; }

        const caps = (track.getCapabilities && track.getCapabilities()) || {};
        const adv = [];

        // Continuous focus / exposure / white balance
        if (caps.focusMode && caps.focusMode.includes('continuous')) adv.push({ focusMode: 'continuous' });
        if (caps.exposureMode && caps.exposureMode.includes('continuous')) adv.push({ exposureMode: 'continuous' });
        if (caps.whiteBalanceMode && caps.whiteBalanceMode.includes('continuous')) adv.push({ whiteBalanceMode: 'continuous' });

        // Slight zoom for small markers
        if (caps.zoom) {
          const z = Math.min(caps.zoom.max || 2.5, 2.5);
          adv.push({ zoom: z });
        }

        try { await track.applyConstraints({ advanced: adv }); }
        catch(e) { /* ignore unsupported constraints */ }
      };
      tick();
    })();
    </script>
  </body>
</html>